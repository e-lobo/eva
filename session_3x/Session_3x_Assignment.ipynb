{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Session_3x_Assignment.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-SECx0X8y165"
      },
      "source": [
        "# Full Network Model\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Make a network that has:\n",
        "\n",
        "\n",
        "1. 6 Convolution layers with these kernels (10, 10, 20, 20, 30)\n",
        "2. no fully connected layer (you probably may have to use the Global Average Pooling layer)\n",
        "3. uses EMNIST as the dataset\n",
        "4. uses a maximum of 2 max-pooling layers\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yj5efVPay-C2"
      },
      "source": [
        "from __future__ import print_function\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PyC_TWyOzLaO"
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1,10, 3, padding=0) # Input => 28 ; Output => 26 ; Receptive Field => 3 \n",
        "  \n",
        "        self.conv2 = nn.Conv2d(10,10, 3, padding=0) # Input => 26 ; Output => 24 ; Receptive Field => 5\n",
        "        \n",
        "        self.pool1 = nn.MaxPool2d(2, 2) # Input => 24 ; Output => 12 ; Receptive Field => 10\n",
        "\n",
        "        self.conv3 = nn.Conv2d(10, 20, 3, padding=0) # Input => 12 ; Output => 10 ; Receptive Field => 12\n",
        "        \n",
        "        self.conv4 = nn.Conv2d(20, 20, 3, padding=0) # Input => 10 ; Output => 8 ; Receptive Field => 14\n",
        "       \n",
        "        self.conv5 = nn.Conv2d(20, 30, 3, padding=0) # Input => 8 ; Output => 6 ; Receptive Field => 16\n",
        "       \n",
        "        self.pool2 = nn.MaxPool2d(2, 2) # Input => 6 ; Output => 3 ; Receptive Field => 32\n",
        "\n",
        "        self.conv6 = nn.Conv2d(30, 62, 3) # Input => 3 ; Output => 1 ; Receptive Field => 35\n",
        "       \n",
        "        self.aap = nn.AdaptiveAvgPool2d((5,1)) # Global Average pooling\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool1(F.relu(self.conv2(F.relu(self.conv1(x)))))\n",
        "        x = F.relu(self.conv4(F.relu(self.conv3(x))))\n",
        "        x = self.pool2((F.relu(self.conv5(x))))\n",
        "        x = self.conv6(x)\n",
        "        x = self.aap(x)\n",
        "        x = x.view(-1, 10)\n",
        "        return F.log_softmax(x)"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DMn_2kfJ1Npx",
        "outputId": "593e6629-a76c-4663-c202-f0ca5d5ed38b"
      },
      "source": [
        "!pip install torchsummary\n",
        "from torchsummary import summary\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "model = Net().to(device)\n",
        "summary(model, input_size=(1, 28, 28))"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.6/dist-packages (1.5.1)\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 10, 26, 26]             100\n",
            "            Conv2d-2           [-1, 10, 24, 24]             910\n",
            "         MaxPool2d-3           [-1, 10, 12, 12]               0\n",
            "            Conv2d-4           [-1, 20, 10, 10]           1,820\n",
            "            Conv2d-5             [-1, 20, 8, 8]           3,620\n",
            "            Conv2d-6             [-1, 30, 6, 6]           5,430\n",
            "         MaxPool2d-7             [-1, 30, 3, 3]               0\n",
            "            Conv2d-8             [-1, 62, 1, 1]          16,802\n",
            " AdaptiveAvgPool2d-9             [-1, 62, 5, 1]               0\n",
            "================================================================\n",
            "Total params: 28,682\n",
            "Trainable params: 28,682\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.14\n",
            "Params size (MB): 0.11\n",
            "Estimated Total Size (MB): 0.26\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:29: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}